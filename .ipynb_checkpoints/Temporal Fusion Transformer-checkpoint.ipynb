{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048c2588",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06dde3",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c561c",
   "metadata": {},
   "source": [
    "## Load libraries & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a76b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalFusionDataset(Dataset):\n",
    "    def __init__(self, data, entity_column, time_column, target_column, \n",
    "                 input_columns, encoder_steps, decoder_steps):\n",
    "        \"\"\"\n",
    "          data (pd.DataFrame): dataframe containing raw data\n",
    "          entity_column (str): name of column containing entity data\n",
    "          time_column (str): name of column containing date data\n",
    "          target_column (str): name of column we need to predict\n",
    "          input_columns (list): list of string names of columns used as input\n",
    "          encoder_steps (int): number of known past time steps used for forecast. Equivalent to size of LSTM encoder\n",
    "          decoder_steps (int): number of input time steps used for each forecast date. Equivalent to the width N of the decoder\n",
    "        \"\"\"\n",
    "\n",
    "        self.encoder_steps = encoder_steps\n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        entity = []\n",
    "        time = []\n",
    "\n",
    "        for _, entity_group in data.groupby(entity_column):\n",
    "\n",
    "            data_time_steps = len(entity_group)\n",
    "\n",
    "            if data_time_steps >= decoder_steps:\n",
    "                x = entity_group[input_columns].copy().values\n",
    "                inputs.append(np.stack([x[i:data_time_steps - (decoder_steps - 1) + i, :] for i in range(decoder_steps)], axis=1))\n",
    "\n",
    "                y = entity_group[[target_column]].copy().values\n",
    "                outputs.append(np.stack([y[i:data_time_steps - (decoder_steps - 1) + i, :] for i in range(decoder_steps)], axis=1))\n",
    "\n",
    "                e = entity_group[[entity_column]].copy().values\n",
    "                entity.append(np.stack([e[i:data_time_steps - (decoder_steps - 1) + i, :] for i in range(decoder_steps)], axis=1))\n",
    "\n",
    "                t = entity_group[[time_column]].copy().values\n",
    "                time.append(np.stack([t[i:data_time_steps - (decoder_steps - 1) + i, :] for i in range(decoder_steps)], axis=1))\n",
    "\n",
    "        else:\n",
    "            inputs.append(None)\n",
    "            outputs.append(None)\n",
    "            entity.append(None)\n",
    "            time.append(None)\n",
    "\n",
    "        self.inputs = np.concatenate(inputs, axis=0)\n",
    "        self.outputs = np.concatenate(outputs, axis=0)[:, encoder_steps:, :]\n",
    "        self.entity = np.concatenate(entity, axis=0)\n",
    "        #self.time = np.concatenate(time, axis=0)\n",
    "        self.active_inputs = np.ones_like(outputs)\n",
    "\n",
    "        self.sampled_data = {\n",
    "            'inputs': self.inputs,\n",
    "            'outputs': self.outputs[:, self.encoder_steps:, :],\n",
    "            'active_entries': np.ones_like(self.outputs[:, self.encoder_steps:, :]),\n",
    "            #'time': self.time,\n",
    "            'identifier': self.entity\n",
    "        }\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        s = {\n",
    "        'inputs': self.inputs[index],\n",
    "        'outputs': self.outputs[index], #self.outputs[index, self.encoder_steps:, :],\n",
    "        'active_entries': np.ones_like(self.outputs[index]), # np.ones_like(self.outputs[index, self.encoder_steps:, :]),\n",
    "        #'time': self.time[index],\n",
    "        'identifier': self.entity[index]\n",
    "        }\n",
    "\n",
    "        return s\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1ce1e",
   "metadata": {},
   "source": [
    "## Basic Components\n",
    "\n",
    "The Temporal Fusion Transfomer architecture is composed of multiple components. We will start by building these components individually so that we then can use them on different types of problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ec2c3",
   "metadata": {},
   "source": [
    "### Helper components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalLayer(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        \"\"\"\n",
    "        Wrapper that collapses input of dimensions timesteps*samples*hidden_state \n",
    "        to (timesteps*samples)*hidden_state and applies a layer to every temporal\n",
    "        slice of the input.\n",
    "        \"\"\"\n",
    "        super(TemporalLayer, self).__init__()\n",
    "\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        timesteps, samples = x.size(0), x.size(1)\n",
    "        x = x.view(timesteps * samples, -1)\n",
    "        x = self.module(x)\n",
    "        x = x.view(timesteps, samples, x.size(-1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed8d94",
   "metadata": {},
   "source": [
    "### Gated Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    \"\"\"\n",
    "      The Gated Linear Unit GLU(a,b) = mult(a,sigmoid(b)) is common in NLP \n",
    "      architectures like the Gated CNN. Here sigmoid(b) corresponds to a gate \n",
    "      that controls what information from a is passed to the following layer. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        super(GLU, self).__init__()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.a = nn.Linear(input_size, input_size)\n",
    "        self.b = nn.Linear(input_size, input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        gate = self.sigmoid(self.b(x))\n",
    "        x = self.a(x)\n",
    "        \n",
    "        return torch.mul(gate, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d75c3",
   "metadata": {},
   "source": [
    "### Gated Residual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedResidualNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "      The Gated Residual Network gives the model flexibility to apply non-linear\n",
    "      processing only when needed. It is difficult to know beforehand which\n",
    "      variables are relevant and in some cases simpler models can be beneficial.\n",
    "\n",
    "      GRN(a, c) = LayerNorm(a + GLU(eta_1)) # Dropout is applied to eta_1\n",
    "        eta_1 = W_1*eta_2 + b_1\n",
    "        eta_2 = ELU(W_2*a + W_3*c + b_2)\n",
    "    \"\"\"\n",
    "    def __init__():\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
