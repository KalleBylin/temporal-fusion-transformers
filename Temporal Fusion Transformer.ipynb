{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703731b9",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6b940",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da2790",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861d036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8efd5a2",
   "metadata": {},
   "source": [
    "## Basic Components\n",
    "\n",
    "The Temporal Fusion Transfomer architecture is composed of multiple components. We will start by building these components individually so that we then can use them on different types of problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e31d6",
   "metadata": {},
   "source": [
    "### Gated Residual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d946a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    \"\"\"\n",
    "      The Gated Linear Unit GLU(a,b) = mult(a,sigmoid(b)) is common in NLP \n",
    "      architectures like the Gated CNN. Here sigmoid(b) corresponds to a gate \n",
    "      that controls what information from a is passed to the following layer. \n",
    "\n",
    "      Args:\n",
    "          input_size (int): number defining input and output size of the gate\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input\n",
    "        self.a = nn.Linear(input_size, input_size)\n",
    "\n",
    "        # Gate\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.b = nn.Linear(input_size, input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.tensor): tensor passing through the gate\n",
    "        \"\"\"\n",
    "        gate = self.sigmoid(self.b(x))\n",
    "        x = self.a(x)\n",
    "        \n",
    "        return torch.mul(gate, x)\n",
    "\n",
    "\n",
    "class TemporalLayer(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Collapses input of dim T*N*H to (T*N)*H, and applies to a module.\n",
    "        Allows handling of variable sequence lengths and minibatch sizes.\n",
    "\n",
    "        Similar to TimeDistributed in Keras, it is a wrapper that makes it possible\n",
    "        to apply a layer to every temporal slice of an input.\n",
    "        \"\"\"\n",
    "        self.module = module\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.tensor): tensor with time steps to pass through the same layer.\n",
    "        \"\"\"\n",
    "        t, n = x.size(0), x.size(1)\n",
    "        x = x.reshape(t * n, -1)\n",
    "        x = self.module(x)\n",
    "        x = x.reshape(t, n, x.size(-1))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "      The Gated Residual Network gives the model flexibility to apply non-linear\n",
    "      processing only when needed. It is difficult to know beforehand which\n",
    "      variables are relevant and in some cases simpler models can be beneficial.\n",
    "\n",
    "      GRN(a, c) = LayerNorm(a + GLU(eta_1)) # Dropout is applied to eta_1\n",
    "        eta_1 = W_1*eta_2 + b_1\n",
    "        eta_2 = ELU(W_2*a + W_3*c + b_2)\n",
    "      \n",
    "      Args:\n",
    "          input_size (int): Size of the input\n",
    "          hidden_size (int): Size of the hidden layer\n",
    "          output_size (int): Size of the output layer\n",
    "          dropout (float): Fraction between 0 and 1 corresponding to the degree of dropout used\n",
    "          context_size (int): Size of the static context vector\n",
    "          is_temporal (bool): Flag to decide if TemporalLayer has to be used or not\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout, context_size=None, is_temporal=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.context_size = context_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.is_temporal = is_temporal\n",
    "        \n",
    "        if self.is_temporal:\n",
    "            if self.input_size != self.output_size:\n",
    "                self.skip_layer = TemporalLayer(nn.Linear(self.input_size, self.output_size))\n",
    "\n",
    "            # Context vector c\n",
    "            if self.context_size != None:\n",
    "                self.c = TemporalLayer(nn.Linear(self.context_size, self.hidden_size, bias=False))\n",
    "\n",
    "            # Dense & ELU\n",
    "            self.dense1 = TemporalLayer(nn.Linear(self.input_size, self.hidden_size))\n",
    "            self.elu = nn.ELU()\n",
    "\n",
    "            # Dense & Dropout\n",
    "            self.dense2 = TemporalLayer(nn.Linear(self.hidden_size,  self.output_size))\n",
    "            self.dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "            # Gate, Add & Norm\n",
    "            self.gate = TemporalLayer(GLU(self.output_size))\n",
    "            self.layer_norm = TemporalLayer(nn.BatchNorm1d(self.output_size))\n",
    "\n",
    "        else:\n",
    "            if self.input_size != self.output_size:\n",
    "                self.skip_layer = nn.Linear(self.input_size, self.output_size)\n",
    "\n",
    "            # Context vector c\n",
    "            if self.context_size != None:\n",
    "                self.c = nn.Linear(self.context_size, self.hidden_size, bias=False)\n",
    "\n",
    "            # Dense & ELU\n",
    "            self.dense1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.elu = nn.ELU()\n",
    "\n",
    "            # Dense & Dropout\n",
    "            self.dense2 = nn.Linear(self.hidden_size,  self.output_size)\n",
    "            self.dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "            # Gate, Add & Norm\n",
    "            self.gate = GLU(self.output_size)\n",
    "            self.layer_norm = nn.BatchNorm1d(self.output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, c=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.tensor): tensor thas passes through the GRN\n",
    "            c (torch.tensor): Optional static context vector\n",
    "        \"\"\"\n",
    "\n",
    "        if self.input_size!=self.output_size:\n",
    "            a = self.skip_layer(x)\n",
    "        else:\n",
    "            a = x\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "\n",
    "        if c != None:\n",
    "            c = self.c(c.unsqueeze(1))\n",
    "            x += c\n",
    "\n",
    "        eta_2 = self.elu(x)\n",
    "        \n",
    "        eta_1 = self.dense2(eta_2)\n",
    "        eta_1 = self.dropout(eta_1)\n",
    "\n",
    "        gate = self.gate(eta_1)\n",
    "        gate += a\n",
    "        x = self.layer_norm(gate)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9358d3",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc01d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs(df):\n",
    "    out = df.copy()\n",
    "    out[['log_vol', 'open_to_close', 'days_from_start']] = real_scalers.transform(df[['log_vol', 'open_to_close', 'days_from_start']].values)\n",
    "\n",
    "    for col in ['Symbol', 'day_of_week', 'day_of_month', 'week_of_year', 'month', 'Region']:\n",
    "        string_df = df[col].apply(str)\n",
    "        out[col] = categorical_scalers[col].transform(string_df)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1d8d3",
   "metadata": {},
   "source": [
    "The dataset code is decoupled from our model training code for better readability and modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95733fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570f662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFT_Dataset(Dataset):\n",
    "    def __init__(self, data, entity_column, time_column, target_column, \n",
    "                 input_columns, encoder_steps, decoder_steps):\n",
    "        \"\"\"\n",
    "          data (pd.DataFrame): dataframe containing raw data\n",
    "          entity_column (str): name of column containing entity data\n",
    "          time_column (str): name of column containing date data\n",
    "          target_column (str): name of column we need to predict\n",
    "          input_columns (list): list of string names of columns used as input\n",
    "          encoder_steps (int): number of known past time steps used for forecast. Equivalent to size of LSTM encoder\n",
    "          decoder_steps (int): number of input time steps used for each forecast date. Equivalent to the width N of the decoder\n",
    "        \"\"\"\n",
    "        \n",
    "        self.encoder_steps = encoder_steps\n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        \n",
    "        \n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        entity = []\n",
    "        time = []\n",
    "\n",
    "        for _, entity_group in data.groupby(entity_column):\n",
    "            \n",
    "            data_time_steps = len(entity_group)\n",
    "\n",
    "            if data_time_steps >= decoder_steps:\n",
    "                x = entity_group[input_columns].copy().values\n",
    "                inputs.append(np.stack([x[i:data_time_steps - (decoder_steps - 1) + i, :] for i in range(decoder_steps)], axis=1))\n",
    "\n",
    "                y = entity_group[[target_column]].copy().values\n",
    "                outputs.append(np.stack([y[i:data_time_steps - (decoder_steps - 1) + i, :] for i in range(decoder_steps)], axis=1))\n",
    "\n",
    "                e = entity_group[[entity_column]].copy().values\n",
    "                entity.append(np.stack([e[i:data_time_steps - (decoder_steps - 1) + i, :] for i in range(decoder_steps)], axis=1))\n",
    "\n",
    "                t = entity_group[[time_column]].copy().values\n",
    "                time.append(np.stack([t[i:data_time_steps - (decoder_steps - 1) + i, :] for i in range(decoder_steps)], axis=1))\n",
    "\n",
    "            else:\n",
    "                inputs.append(None)\n",
    "                outputs.append(None)\n",
    "                entity.append(None)\n",
    "                time.append(None)\n",
    "\n",
    "        self.inputs = np.concatenate(inputs, axis=0)\n",
    "        self.outputs = np.concatenate(outputs, axis=0)[:, encoder_steps:, :]\n",
    "        self.entity = np.concatenate(entity, axis=0)\n",
    "        #self.time = np.concatenate(time, axis=0)\n",
    "        self.active_inputs = np.ones_like(outputs)\n",
    "\n",
    "        self.sampled_data = {\n",
    "            'inputs': self.inputs,\n",
    "            'outputs': self.outputs[:, self.encoder_steps:, :],\n",
    "            'active_entries': np.ones_like(self.outputs[:, self.encoder_steps:, :]),\n",
    "            #'time': self.time,\n",
    "            'identifier': self.entity\n",
    "        }\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        s = {\n",
    "        'inputs': self.inputs[index],\n",
    "        'outputs': self.outputs[index], \n",
    "        'active_entries': np.ones_like(self.outputs[index]), \n",
    "        #'time': self.time[index],\n",
    "        'identifier': self.entity[index]\n",
    "        }\n",
    "\n",
    "        return s\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13bbb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../formatted_omi_vol.csv', index_col=0)\n",
    "\n",
    "train = raw_data[raw_data['year'] < 2016]\n",
    "valid = raw_data.loc[(raw_data['year'] >= 2016) & (raw_data['year'] < 2018)]\n",
    "test = raw_data.loc[(raw_data['year'] >= 2018) & (raw_data.index <= '2019-06-28')]\n",
    "\n",
    "real_scalers = StandardScaler().fit(train[['log_vol', 'open_to_close', 'days_from_start']].values)\n",
    "target_scaler = StandardScaler().fit(train[['log_vol']].values)\n",
    "\n",
    "categorical_scalers = {}\n",
    "num_classes = []\n",
    "for col in ['Symbol', 'day_of_week', 'day_of_month', 'week_of_year', 'month', 'Region']:\n",
    "    srs = train[col].apply(str) \n",
    "    categorical_scalers[col] = LabelEncoder().fit(srs.values)\n",
    "    num_classes.append(srs.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbec3278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 109882 entries, 2000-01-03 00:00:00+00:00 to 2015-12-31 00:00:00+00:00\n",
      "Data columns (total 29 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   Symbol           109882 non-null  object \n",
      " 1   rv10             109882 non-null  float64\n",
      " 2   nobs             109882 non-null  float64\n",
      " 3   medrv            109881 non-null  float64\n",
      " 4   rk_parzen        109882 non-null  float64\n",
      " 5   rv5              109882 non-null  float64\n",
      " 6   bv_ss            109882 non-null  float64\n",
      " 7   rk_th2           109882 non-null  float64\n",
      " 8   bv               109882 non-null  float64\n",
      " 9   open_time        109882 non-null  float64\n",
      " 10  close_price      109882 non-null  float64\n",
      " 11  rv5_ss           109882 non-null  float64\n",
      " 12  rv10_ss          109882 non-null  float64\n",
      " 13  close_time       109882 non-null  float64\n",
      " 14  rsv_ss           109882 non-null  float64\n",
      " 15  rk_twoscale      109882 non-null  float64\n",
      " 16  rsv              109882 non-null  float64\n",
      " 17  open_price       109882 non-null  float64\n",
      " 18  open_to_close    109882 non-null  float64\n",
      " 19  date             109882 non-null  object \n",
      " 20  days_from_start  109882 non-null  int64  \n",
      " 21  day_of_week      109882 non-null  int64  \n",
      " 22  day_of_month     109882 non-null  int64  \n",
      " 23  week_of_year     109882 non-null  int64  \n",
      " 24  month            109882 non-null  int64  \n",
      " 25  year             109882 non-null  int64  \n",
      " 26  categorical_id   109882 non-null  object \n",
      " 27  log_vol          109882 non-null  float64\n",
      " 28  Region           109882 non-null  object \n",
      "dtypes: float64(19), int64(6), object(4)\n",
      "memory usage: 25.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2bf66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>rv10</th>\n",
       "      <th>nobs</th>\n",
       "      <th>medrv</th>\n",
       "      <th>rk_parzen</th>\n",
       "      <th>rv5</th>\n",
       "      <th>bv_ss</th>\n",
       "      <th>rk_th2</th>\n",
       "      <th>bv</th>\n",
       "      <th>open_time</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>categorical_id</th>\n",
       "      <th>log_vol</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:00:00+00:00</th>\n",
       "      <td>.AEX</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>90101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>.AEX</td>\n",
       "      <td>-8.946668</td>\n",
       "      <td>EMEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04 00:00:00+00:00</th>\n",
       "      <td>.AEX</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>90416.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>.AEX</td>\n",
       "      <td>-8.510686</td>\n",
       "      <td>EMEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05 00:00:00+00:00</th>\n",
       "      <td>.AEX</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>90016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>.AEX</td>\n",
       "      <td>-7.619135</td>\n",
       "      <td>EMEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06 00:00:00+00:00</th>\n",
       "      <td>.AEX</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>90016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>.AEX</td>\n",
       "      <td>-8.398790</td>\n",
       "      <td>EMEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07 00:00:00+00:00</th>\n",
       "      <td>.AEX</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>90046.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>.AEX</td>\n",
       "      <td>-8.885257</td>\n",
       "      <td>EMEA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Symbol      rv10    nobs     medrv  rk_parzen  \\\n",
       "2000-01-03 00:00:00+00:00   .AEX  0.000178  1795.0  0.000050   0.000179   \n",
       "2000-01-04 00:00:00+00:00   .AEX  0.000261  1785.0  0.000075   0.000423   \n",
       "2000-01-05 00:00:00+00:00   .AEX  0.000714  1801.0  0.000166   0.000324   \n",
       "2000-01-06 00:00:00+00:00   .AEX  0.000182  1799.0  0.000152   0.000219   \n",
       "2000-01-07 00:00:00+00:00   .AEX  0.000157  1798.0  0.000039   0.000155   \n",
       "\n",
       "                                rv5     bv_ss    rk_th2        bv  open_time  \\\n",
       "2000-01-03 00:00:00+00:00  0.000130  0.000100  0.000102  0.000100    90101.0   \n",
       "2000-01-04 00:00:00+00:00  0.000201  0.000207  0.000201  0.000207    90416.0   \n",
       "2000-01-05 00:00:00+00:00  0.000491  0.000361  0.000345  0.000361    90016.0   \n",
       "2000-01-06 00:00:00+00:00  0.000225  0.000258  0.000221  0.000258    90016.0   \n",
       "2000-01-07 00:00:00+00:00  0.000138  0.000130  0.000123  0.000130    90046.0   \n",
       "\n",
       "                           ...        date  days_from_start  day_of_week  \\\n",
       "2000-01-03 00:00:00+00:00  ...  2000-01-03                0            0   \n",
       "2000-01-04 00:00:00+00:00  ...  2000-01-04                1            1   \n",
       "2000-01-05 00:00:00+00:00  ...  2000-01-05                2            2   \n",
       "2000-01-06 00:00:00+00:00  ...  2000-01-06                3            3   \n",
       "2000-01-07 00:00:00+00:00  ...  2000-01-07                4            4   \n",
       "\n",
       "                           day_of_month  week_of_year  month  year  \\\n",
       "2000-01-03 00:00:00+00:00             3             1      1  2000   \n",
       "2000-01-04 00:00:00+00:00             4             1      1  2000   \n",
       "2000-01-05 00:00:00+00:00             5             1      1  2000   \n",
       "2000-01-06 00:00:00+00:00             6             1      1  2000   \n",
       "2000-01-07 00:00:00+00:00             7             1      1  2000   \n",
       "\n",
       "                           categorical_id   log_vol Region  \n",
       "2000-01-03 00:00:00+00:00            .AEX -8.946668   EMEA  \n",
       "2000-01-04 00:00:00+00:00            .AEX -8.510686   EMEA  \n",
       "2000-01-05 00:00:00+00:00            .AEX -7.619135   EMEA  \n",
       "2000-01-06 00:00:00+00:00            .AEX -8.398790   EMEA  \n",
       "2000-01-07 00:00:00+00:00            .AEX -8.885257   EMEA  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e28a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transform_inputs(train)\n",
    "valid = transform_inputs(valid)\n",
    "test = transform_inputs(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee07afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
